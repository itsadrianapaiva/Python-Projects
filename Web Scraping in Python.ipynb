{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d53e69-6e72-4a14-ba0e-cf2d575bab06",
   "metadata": {},
   "source": [
    "# Scraping Data from a Real Website + Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1f1e5-afa7-4de7-b6c8-35ed5dd989d0",
   "metadata": {},
   "source": [
    "This project involves scraping data from the Wikipedia page \"List of largest companies in the United States by revenue\" using Python. The objective is to extract information about the largest companies by revenue, including details such as company names, revenue figures, and industry classifications. The extracted data will be processed and analyzed using the pandas library to provide insights and facilitate further data analysis.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "Web Scraping: Utilize libraries such as requests and BeautifulSoup to fetch and parse HTML content from the Wikipedia page.\n",
    "\n",
    "Data Extraction: Extract relevant data points including company names, revenue, and industry categories.\n",
    "\n",
    "\n",
    "Future work:\n",
    "Data Processing: Use pandas for manipulation and analysis.\n",
    "Output: Generate a clean, structured analysis through visualizations using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436dce1-4da1-40af-b425-1da9390310b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Pulling the information from the URL and turning into readable text\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'\n",
    "\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html')\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94f926-3a01-411e-95be-d107d4f48828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Located the table I want and now I'll pull the table from the web page using index\n",
    "\n",
    "soup.find_all('table')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7869ce-69ce-43b3-9dba-593c1268a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "table  = soup.find_all('table')[1]\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8504be1d-bf17-4d94-a16f-4751c0c6c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<th>Rank\n",
      "</th>, <th>Name\n",
      "</th>, <th>Industry\n",
      "</th>, <th>Revenue <br/>(USD millions)\n",
      "</th>, <th>Revenue growth\n",
      "</th>, <th>Employees\n",
      "</th>, <th>Headquarters\n",
      "</th>]\n"
     ]
    }
   ],
   "source": [
    "# Getting the table headers\n",
    "\n",
    "world_titles = table.find_all('th')\n",
    "print(world_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2190a48-c6a5-457d-abcb-f3ac1c8011ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rank', 'Name', 'Industry', 'Revenue (USD millions)', 'Revenue growth', 'Employees', 'Headquarters']\n"
     ]
    }
   ],
   "source": [
    "# List comprehension to pull out each table title as text\n",
    "# and cleaning the results with .strip()\n",
    "\n",
    "world_table_titles = [title.text.strip() for title in world_titles]\n",
    "print(world_table_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30ccf0c-ba9e-4160-adf2-13a930299488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While reviewing titles I noticed it ended up pulling information from the second table in the page which is not what I want\n",
    "# I had to go back and review the code to debug and I fixed the error which was on te line 27\n",
    "# where I had to find all on the table and it was previously as find all on soup.\n",
    "\n",
    "# Now we are good to pull the data into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1383f80-5806-4ca4-9433-63c1ea52b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f908e332-4e19-49c7-b7fe-9e8aff324cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Revenue (USD millions)</th>\n",
       "      <th>Revenue growth</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Headquarters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rank, Name, Industry, Revenue (USD millions), Revenue growth, Employees, Headquarters]\n",
       "Index: []"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = world_table_titles)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310dee77-037e-4882-86ca-d4808ef6dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I'm going to go back to the web page to pull up the rows from the table\n",
    "\n",
    "column_data = table.find_all('tr')\n",
    "print(column_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6d72ead2-3a65-4019-9bdb-46ccafe09812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's time to fill in the dataframe but I encoutered a error when trying to iterate each data row to the existing dataframe\n",
    "# So I try a different approach wich is creating a new dataframe using a list comprehension to gather all data at once \n",
    "# and replace the existing empty dataframe. \n",
    "# I also encountered another error which was an empty row on the top\n",
    "# To fix that bug I added an index to the column data to point to where the loop should start\n",
    "\n",
    "rows_to_add = [\n",
    "    [data.text.strip() for data in row.find_all('td')]\n",
    "    for row in column_data[1:101]\n",
    "]\n",
    "df = pd.DataFrame(rows_to_add, columns=world_table_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e5bd3849-8f9c-4cf6-a2f0-222707f8d0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Revenue (USD millions)</th>\n",
       "      <th>Revenue growth</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Headquarters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Retail</td>\n",
       "      <td>611,289</td>\n",
       "      <td>6.7%</td>\n",
       "      <td>2,100,000</td>\n",
       "      <td>Bentonville, Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Retail and cloud computing</td>\n",
       "      <td>513,983</td>\n",
       "      <td>9.4%</td>\n",
       "      <td>1,540,000</td>\n",
       "      <td>Seattle, Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>Petroleum industry</td>\n",
       "      <td>413,680</td>\n",
       "      <td>44.8%</td>\n",
       "      <td>62,000</td>\n",
       "      <td>Spring, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Electronics industry</td>\n",
       "      <td>394,328</td>\n",
       "      <td>7.8%</td>\n",
       "      <td>164,000</td>\n",
       "      <td>Cupertino, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>324,162</td>\n",
       "      <td>12.7%</td>\n",
       "      <td>400,000</td>\n",
       "      <td>Minnetonka, Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Best Buy</td>\n",
       "      <td>Retail</td>\n",
       "      <td>46,298</td>\n",
       "      <td>10.6%</td>\n",
       "      <td>71,100</td>\n",
       "      <td>Richfield, Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Bristol-Myers Squibb</td>\n",
       "      <td>Pharmaceutical industry</td>\n",
       "      <td>46,159</td>\n",
       "      <td>0.5%</td>\n",
       "      <td>34,300</td>\n",
       "      <td>New York City, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>United Airlines</td>\n",
       "      <td>Airline</td>\n",
       "      <td>44,955</td>\n",
       "      <td>82.5%</td>\n",
       "      <td>92,795</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Thermo Fisher Scientific</td>\n",
       "      <td>Laboratory instruments</td>\n",
       "      <td>44,915</td>\n",
       "      <td>14.5%</td>\n",
       "      <td>130,000</td>\n",
       "      <td>Waltham, Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Qualcomm</td>\n",
       "      <td>Technology</td>\n",
       "      <td>44,200</td>\n",
       "      <td>31.7%</td>\n",
       "      <td>51,000</td>\n",
       "      <td>San Diego, California</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      Name                    Industry  \\\n",
       "0     1                   Walmart                      Retail   \n",
       "1     2                    Amazon  Retail and cloud computing   \n",
       "2     3                ExxonMobil          Petroleum industry   \n",
       "3     4                     Apple        Electronics industry   \n",
       "4     5        UnitedHealth Group                  Healthcare   \n",
       "..  ...                       ...                         ...   \n",
       "95   96                  Best Buy                      Retail   \n",
       "96   97      Bristol-Myers Squibb     Pharmaceutical industry   \n",
       "97   98           United Airlines                     Airline   \n",
       "98   99  Thermo Fisher Scientific      Laboratory instruments   \n",
       "99  100                  Qualcomm                  Technology   \n",
       "\n",
       "   Revenue (USD millions) Revenue growth  Employees             Headquarters  \n",
       "0                 611,289           6.7%  2,100,000    Bentonville, Arkansas  \n",
       "1                 513,983           9.4%  1,540,000      Seattle, Washington  \n",
       "2                 413,680          44.8%     62,000            Spring, Texas  \n",
       "3                 394,328           7.8%    164,000    Cupertino, California  \n",
       "4                 324,162          12.7%    400,000    Minnetonka, Minnesota  \n",
       "..                    ...            ...        ...                      ...  \n",
       "95                 46,298          10.6%     71,100     Richfield, Minnesota  \n",
       "96                 46,159           0.5%     34,300  New York City, New York  \n",
       "97                 44,955          82.5%     92,795        Chicago, Illinois  \n",
       "98                 44,915          14.5%    130,000   Waltham, Massachusetts  \n",
       "99                 44,200          31.7%     51,000    San Diego, California  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c064a8b3-6cb9-43e1-b265-45691fd5f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It worked perfectly, so It's time to export as a csv file\n",
    "\n",
    "df.to_csv(r'C:\\Users\\gusta\\Desktop\\Dri - Data Bootcamp\\Companies.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff67e0e-8018-4358-8532-af3914e5ba8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5b1cd1-c295-4ef5-b34b-7bbed9882588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c30e5-ba93-4e47-8a9d-e17ece391770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785ee18-780e-4659-9b49-c00bf06fe04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae414900-1aec-4082-a371-f8efdd491810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae72b9-cc5c-4eb7-b3b2-a6a9504823ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71df5d-ad0d-4bbf-b5fa-867008f2d4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561816f-b734-4346-bfd2-196ca9c983b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a06a70-31bc-4554-8ed9-fa850943cf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982a0ac-0488-4380-b66f-9060aed43600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0cc77-4dcd-4c6b-a115-5c5643ca08e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9969b6-64ad-4bfe-bc2b-3b7fe746154a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51464d31-0bd2-4d4d-9ee0-cf3d816f2490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a46f6-e5e7-45e2-b4ae-edb912856e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
